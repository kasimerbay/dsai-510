{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b26fc57",
   "metadata": {},
   "source": [
    "# Lecture 2 - DSAI510 Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c510f719",
   "metadata": {},
   "source": [
    "# Data Types in Python\n",
    "\n",
    "Understanding data types is crucial in data science for efficient data processing, analysis, and modeling. Data in Python can be classified into:\n",
    "- Numeric (int or float)\n",
    "- Categorical\n",
    "- DateTime\n",
    "- String (text)\n",
    "- Boolean (True or False)\n",
    "\n",
    "Numbers in some context may be a categorical value rather than numeric value. For example, age is a numeric data type because it represents a quantifiable amount with inherent ordinality (e.g., 25 years is older than 24 years). However, numbers like 1, 2, 3, ... written on boxes to label them do not represent a quantifiable amount or inherent ordinality in the context of the boxes' contents. In this scenario, even though the labels are numbers, they act as identifiers or names for the boxes. Thus, these numbers 1, 2, 3, ... on the boxes are of a categorical type. The key distinction here is the context in which the numbers are used. In the case of age, the numbers have a clear ordinal and quantitative meaning. In the case of box labels, the numbers are merely identifiers and don't imply any ordinality or quantity about the boxes' contents. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcabc89",
   "metadata": {},
   "source": [
    "# Data Structures in Python: \n",
    "\n",
    "Data structures are containers that hold multiple data items, possibly of diverse types. \n",
    "- List\n",
    "- Dictionary\n",
    "- Some other we won't use much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integers and Floats\n",
    "int_value = 5\n",
    "float_value = 5.5\n",
    "\n",
    "print(f\"Integer value: {int_value}\")\n",
    "print(f\"Float value: {float_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings\n",
    "string_value = \"Data Science\"\n",
    "print(string_value)\n",
    "print(string_value.upper())\n",
    "print(string_value.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14de1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean\n",
    "cat_is_animal = True\n",
    "print(cat_is_animal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(int_value))\n",
    "print(type(float_value))\n",
    "print(type(string_value))\n",
    "print(type(cat_is_animal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data where the category column is string (not real category yet)\n",
    "data = {'Category': ['A', 'B', 'A', 'C'], 'Size': [1,1,5,10]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Category'].dtype)\n",
    "print(df['Size'].dtype)\n",
    "\n",
    "# Category column is not really categorical yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Category column categorical type (this will be needed for machine learning)\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "print(df['Category'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3373d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DateTime operations with pandas\n",
    "date_series = pd.to_datetime(pd.Series(['2023-09-15', '2023-02-10', '2023-03-05']), format='%Y-%m-%d')\n",
    "print(date_series.dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_example = [1, 2, 3, 4, 5]\n",
    "type(list_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_example = {'Ali': 123, 'Veli': 999, 'Zeki': 444}\n",
    "print(dict_example)\n",
    "type(dict_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66309a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_example['Zeki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d8eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_example = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "print(df_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad49b65",
   "metadata": {},
   "source": [
    "# Python datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1286ed5",
   "metadata": {},
   "source": [
    "## PyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c67137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pydataset package  is not a standard package that ships with Python. So I need to install it manually\n",
    "# Below \"!\" is to send a command to your operating system (MacOs, Linux or Windows) from within Python\n",
    "!pip install pydataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08859ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import package\n",
    "from pydataset import data\n",
    "# List available datasets\n",
    "data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a33c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.show_dimensions', True)\n",
    "# Set the display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# List available datasets\n",
    "display(data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8c1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off \"show all rows\" as it will make your notebook too crowded for large datasets later\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "display(data())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load as a dataframe\n",
    "df = data('Titanic')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a function called glimpse to automate last three lines.\n",
    "def glimpse(df):\n",
    "    print(f\"{df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "    display(df.head())\n",
    "    display(df.tail())\n",
    "    \n",
    "\n",
    "df = data(\"Titanic\")\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9e31a",
   "metadata": {},
   "source": [
    "## Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d90f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(sns.get_dataset_names()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load as a dataframe\n",
    "df = sns.load_dataset('tips')\n",
    "\n",
    "# total_bill is the bill of the table. Size is the table size, like for how many people.\n",
    "glimpse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555cfec9",
   "metadata": {},
   "source": [
    "# Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# List attributes with Python command dir()\n",
    "dir(datasets)\n",
    "\n",
    "# Below, functions starting with load_ typically provide small \n",
    "# standard datasets that come bundled with the library\n",
    "# while functions starting with fetch_ will download \n",
    "# larger datasets from the internet the first time you call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46315b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Load the breast_cancer dataset\n",
    "diabetesdata = load_diabetes()\n",
    "\n",
    "print(diabetesdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetesdata['data']  # or diabetesdata.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7817e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset to a DataFrame\n",
    "df = pd.DataFrame(diabetesdata.data, columns=diabetesdata.feature_names)\n",
    "df\n",
    "\n",
    "# The target variable which quantifies the disease progression is stored in dataset.target. \n",
    "# Let's add it to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the target variable to the DataFrame. This will first create a column named \"target\"\n",
    "df['target'] = diabetesdata.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8c727c",
   "metadata": {},
   "source": [
    "# Natural Language Toolkit | NLTK\n",
    "\n",
    "List of available datasets are given in\n",
    "https://www.nltk.org/nltk_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews\n",
    "\n",
    "#CategorizedPlaintextCorpusReader is a class that provides methods to access and work with text corpora that are organized into categories. \n",
    "# It allows you to handle and explore text data easily, especially when the data is categorized (like the movie reviews dataset, \n",
    "# which is divided into ‘pos’ (positive) and ‘neg’ (negative) categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of file ids for positive and negative reviews\n",
    "positive_fileids = movie_reviews.fileids(categories='pos')\n",
    "negative_fileids = movie_reviews.fileids(categories='neg')\n",
    "\n",
    "# Sample: Display the content of the first positive review and its label\n",
    "sample_positive_review = \" \".join(movie_reviews.words(fileids=positive_fileids[0]))\n",
    "print(\"Review (Positive):\\n\", sample_positive_review[:500], \"...\")  \n",
    "# Displaying the first 500 characters for brevity\n",
    "\n",
    "# Sample: Display the content of the first negative review and its label\n",
    "sample_negative_review = \" \".join(movie_reviews.words(fileids=negative_fileids[5]))\n",
    "print(\"\\nReview (Negative):\\n\", sample_negative_review[:500], \"...\")  \n",
    "# Displaying the first 500 characters for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fef56",
   "metadata": {},
   "source": [
    "## Statmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f211a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the 'fair' dataset as an example\n",
    "fair = sm.datasets.fair.load_pandas().data\n",
    "print(fair.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02796ff",
   "metadata": {},
   "source": [
    "occupation: The occupation of the respondent, coded from 1 to 7. This code represents the following levels of occupation:\n",
    "\t•\t1 = Student\n",
    "\t•\t2 = Farming/Semi-Skilled/Unskilled\n",
    "\t•\t3 = Clerical/Sales/Skilled Manual\n",
    "\t•\t4 = Professional/Managerial\n",
    "\t•\t5 = Other\n",
    "\n",
    "affairs: The number of extramarital affairs reported by the respondent in the past year. This is a continuous variable representing the number of affairs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28f498",
   "metadata": {},
   "source": [
    "## quandl for financial data via API\n",
    "\n",
    "We will pull financial data from the internet by using quandl API. It's free (with rate limits) but first you need to sign up to get your own API key. Here's the link to sign up via NASDAQ page: https://data.nasdaq.com/sign-up   After signing up, your personal API key will display on the screen; it's some gibberish like vnslk_F9502na. Don't share it with anyone. If you miss your API key, you can find it here later: https://data.nasdaq.com/account/profile\n",
    "\n",
    "Available datasets can be reached here: https://data.nasdaq.com/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cd905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fe592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pip first\n",
    "!pip install quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e2707",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Select an Interpreter to start Jupyter\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import quandl\n",
    "from keys import quandl_api_key\n",
    "\n",
    "#myAPIkey= \"lolo\"   # uncomment this line and replace lolo with your own API key \n",
    "\n",
    "quandl.ApiConfig.api_key = quandl_api_key\n",
    "\n",
    "# Fetch Gold price data\n",
    "data = quandl.get(\"LBMA/GOLD\")\n",
    "\n",
    "# Display the first few rows\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6148a62",
   "metadata": {},
   "source": [
    "## Using Web APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160a0735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example doesn't require API KEY. \n",
    "\n",
    "import requests\n",
    "\n",
    "# Define the API endpoint\n",
    "country = \"turkey\"\n",
    "url = f\"https://restcountries.com/v3.1/name/{country}\"\n",
    "\n",
    "# Make the HTTP GET request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON data\n",
    "    data = response.json()[0]  # The API returns a list, so we take the first item\n",
    "    \n",
    "    # Extract and display relevant country data\n",
    "    name = data[\"name\"][\"common\"]\n",
    "    capital = data[\"capital\"][0]\n",
    "    population = data[\"population\"]\n",
    "    area = data[\"area\"]\n",
    "    currencies = \", \".join([currency for currency in data[\"currencies\"]])\n",
    "    \n",
    "    print(f\"Information about {name}:\")\n",
    "    print(f\"Capital: {capital}\")\n",
    "    print(f\"Population: {population}\")\n",
    "    print(f\"Area: {area} sq.km\")\n",
    "    print(f\"Currencies: {currencies}\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. HTTP Status Code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d3132",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58712768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# List all available datasets\n",
    "datasets_list = tfds.list_builders()\n",
    "\n",
    "print(datasets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c563ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Function to display a grid of images\n",
    "def display_images(images, labels, num_rows=2, num_cols=5):\n",
    "    \"\"\"Displays a grid of images.\"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(num_rows * num_cols):\n",
    "        plt.subplot(num_rows, num_cols, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"Label: {labels[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display the first few images from the training set\n",
    "display_images(train_images, train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5d9d9b",
   "metadata": {},
   "source": [
    "# Loading data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3848f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "houses = pd.read_csv(\"houses.csv\")\n",
    "houses\n",
    "\n",
    "# If the data is separated by \";\", then use pd.read_csv(\"hotels.csv\", delimiter=';') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c37164",
   "metadata": {},
   "source": [
    "\"Total\" is total market value of the house. This value usually combines the worth of both the land and the building on it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7b88a",
   "metadata": {},
   "source": [
    "# DATABASES: PostgreSQL Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ab8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sqlalchemy psycopg2\n",
    "\n",
    "# psycopg2 is a popular PostgreSQL database adapter (library) for Python. It allows you to connect to a PostgreSQL database \n",
    "# from your Python application and perform various database operations such as querying, inserting, updating, and deleting data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044a07e",
   "metadata": {},
   "source": [
    "Before the following steps, you need to activate postgres server in the background by using Terminal (MacOS or Linux) or command line in Windows.\n",
    "Then you need to import dvdrental.tar database into your postgre server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a50330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "username = \"postgres\"  # this is usually the default username\n",
    "password = \"foo\"   # replace foo with your password\n",
    "\n",
    "# Create an engine instance\n",
    "engine = create_engine(f'postgresql://{username}:{password}@localhost:5432/dvdrental')\n",
    "\n",
    "try:\n",
    "    connection = engine.connect()\n",
    "    print(\"Successfully connected to the dvdrental database!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f58c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tables = \"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\"\n",
    "tables = pd.read_sql(query_tables, engine)\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a471aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database and retrieve data\n",
    "query = \"SELECT * FROM film LIMIT 5;\"  # This retrieves the first 5 rows from the 'film' table\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database and retrieve data\n",
    "query = \"SELECT * FROM language LIMIT 5;\"  # This retrieves the first 5 rows from the 'film' table\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8414cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
